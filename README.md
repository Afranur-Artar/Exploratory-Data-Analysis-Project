# Exploratory Data Analysis

A typical data science project starts with exploring the data. Exploratory data analysis is the first building block of the data science pipeline. Before moving on to the modeling phase, we need to fully understand the data we work with. The better we understand our data, the more useful we can identify and extract the most useful features, which boost the performance of the model.

### Data Cleaning
It is the first stage of the EDA process. We take the dataset and try to fix the problems we can detect in the data. Data cleaning includes these main steps:
* Removing unnecessary data and outliers.
* Removing duplicates
* Filling the missing values.

### Exploring the Data
This second step is investigating data to discover relationships between different features and patterns in the data. The main tools we use at this stage are statistics and visualization techniques. If we detect new problems in the data during the investigation, we go back to the cleaning stage and clear the data by eliminating the newly found problems.

### Feature engineering
The final step of EDA is feature engineering, where we select the most useful features or create new features from existing features. This phase takes us to the next steps of the data science pipeline. However, if we detect some data problems, we should apply to the data cleaning phase and clean the data again. Also, if we convert existing features or create new ones, we need to go back to the data discovery phase to test whether these new features are useful.

Main steps taken throughout the data exploration process are as follows:
* Variable Identification.
* Univariate Analysis.
* Bi-variate Analysis.
* Missing Values Treatment.
* Outlier Treatment.
* Variable Transformation.
* Variable Creation.
